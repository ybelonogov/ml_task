{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# этап 1 \n",
    "## нахождение на видео человека\n",
    "\n"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"si2nsBzsXZAvnJSGHsRmXz",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"xKSlI0JGy2HZioEJGpzMq0"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!pip install ultralytics\n",
    "!pip install clearml\n",
    "!pip install supervision"
   ],
   "execution_count":54,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: ultralytics in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (8.1.20)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (3.7.1)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (4.9.0.80)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (10.2.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (6.0.1)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (2.30.0)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (1.10.0)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (2.0.1+cpu)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (0.15.2+cpu)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (4.66.1)\r\n",
      "Requirement already satisfied: psutil in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (5.9.8)\r\n",
      "Requirement already satisfied: py-cpuinfo in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: thop>=0.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (0.1.1.post2209072238)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (1.5.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (0.12.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: numpy>=1.20 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (6.1.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\r\n",
      "Requirement already satisfied: filelock in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (1.12)\r\n",
      "Requirement already satisfied: networkx in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\r\n",
      "Requirement already satisfied: six>=1.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Requirement already satisfied: clearml in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (1.14.4)\r\n",
      "Requirement already satisfied: attrs>=18.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (23.2.0)\r\n",
      "Requirement already satisfied: furl>=2.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.1.3)\r\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (4.21.0)\r\n",
      "Requirement already satisfied: numpy>=1.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (1.24.3)\r\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.3.7.post1)\r\n",
      "Requirement already satisfied: Pillow>=4.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (10.2.0)\r\n",
      "Requirement already satisfied: psutil>=3.4.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (5.9.8)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.8.2)\r\n",
      "Requirement already satisfied: PyYAML>=3.12 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (6.0.1)\r\n",
      "Requirement already satisfied: requests>=2.20.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.30.0)\r\n",
      "Requirement already satisfied: six>=1.13.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (1.26.18)\r\n",
      "Requirement already satisfied: pyjwt<2.9.0,>=2.4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.8.0)\r\n",
      "Requirement already satisfied: referencing<0.40 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (0.32.1)\r\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from furl>=2.0.0->clearml) (1.0.1)\r\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (6.1.1)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (2023.12.1)\r\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (1.3.10)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (0.17.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.20.0->clearml) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.20.0->clearml) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.20.0->clearml) (2023.11.17)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6.0->clearml) (3.17.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Requirement already satisfied: supervision in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (0.18.0)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (0.7.1)\r\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (3.7.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (1.24.3)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (4.7.0.72)\r\n",
      "Requirement already satisfied: pyyaml>=5.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (6.0.1)\r\n",
      "Requirement already satisfied: scipy==1.10.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (1.10.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (4.47.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (23.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (6.1.1)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.6.0->supervision) (3.17.0)\r\n",
      "Requirement already satisfied: six>=1.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"7h5GfATsJ0Owpl4TH0vTR6",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"9Xbrseg7AHEAbOznNortIM"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import os"
   ],
   "execution_count":56,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"qXPHkOFoPRqKHVFOmtDjpi",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"QhLR0xVildZuep6oRDTrdN"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model = YOLO(\"yolov8n-pose.pt\")"
   ],
   "execution_count":57,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"GNqtvG1nU96yzhkYChR3ZS",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "image = cv2.imread(\"data\/push_up1.jpg\")\n",
    "results = model(source=\"data\/right.jpg\", show=False, conf=0.3, save=True)\n",
    "results = model(source=\"data\/push_up1.jpg\", show=False, conf=0.3, save=True)\n",
    "\n",
    "result = results[0]\n",
    "results"
   ],
   "execution_count":58,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "image 1\/1 \/data\/notebook_files\/data\/right.jpg: 640x512 1 person, 101.8ms\n",
      "Speed: 3.5ms preprocess, 101.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Results saved to \u001b[1mruns\/pose\/predict4\u001b[0m\n",
      "\n",
      "image 1\/1 \/data\/notebook_files\/data\/push_up1.jpg: 640x288 1 person, 63.6ms\n",
      "Speed: 2.0ms preprocess, 63.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
      "Results saved to \u001b[1mruns\/pose\/predict4\u001b[0m\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/plain":[
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: ultralytics.engine.results.Keypoints object\n",
       "masks: None\n",
       "names: {0: 'person'}\n",
       "obb: None\n",
       "orig_img: array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)\n",
       "orig_shape: (2400, 1080)\n",
       "path: '\/data\/notebook_files\/data\/push_up1.jpg'\n",
       "probs: None\n",
       "save_dir: 'runs\/pose\/predict4'\n",
       "speed: {'preprocess': 1.9638538360595703, 'inference': 63.58981132507324, 'postprocess': 0.9930133819580078}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"GVCuwUWSnIdnCfGXTEfX9C",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def calculate_distance(keypoints, idx1, idx2):\n",
    "    x1, y1 = keypoints.xy[0][idx1]\n",
    "    x2, y2 = keypoints.xy[0][idx2]\n",
    "    if keypoints.has_visible:\n",
    "        distance = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "        return distance\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def choose_side(keypoints):\n",
    "    r_shoulder = calculate_distance(keypoints, 6, 8)\n",
    "    l_shoulder = calculate_distance(keypoints, 5, 7)\n",
    "    return r_shoulder > l_shoulder"
   ],
   "execution_count":58,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"PxNZ9he641HX8CZ33QStc7",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First\n",
    "    b = np.array(b)  # Mid\n",
    "    c = np.array(c)  # End\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 \/ np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle "
   ],
   "execution_count":59,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"UsTsh1M0hx0WEqMifLbUYP",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def get_push_up_angle(keypoints):\n",
    "    if side:\n",
    "        angle = calculate_angle(keypoints.xy[0][6],\n",
    "                                keypoints.xy[0][8],\n",
    "                                keypoints.xy[0][12], )\n",
    "    else:\n",
    "        angle = calculate_angle(keypoints.xy[0][5],\n",
    "                                keypoints.xy[0][7],\n",
    "                                keypoints.xy[0][11], )\n",
    "    return angle\n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "execution_count":60,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"almvprBBw9mv9gWj8LgWNY",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def check_position_body_line(keypoints):\n",
    "    if side:\n",
    "        #распремлена поясница\n",
    "        angle1 =  calculate_angle(keypoints.xy[0][6],\n",
    "                                keypoints.xy[0][12],\n",
    "                                keypoints.xy[0][14],)\n",
    "        #распрямлены ноги\n",
    "        angle2 =  calculate_angle(keypoints.xy[0][12],\n",
    "                                keypoints.xy[0][14],\n",
    "                                keypoints.xy[0][16],)\n",
    "        #изгиб локтя\n",
    "        angle3 = calculate_angle(keypoints.xy[0][6],\n",
    "                                keypoints.xy[0][8],\n",
    "                                keypoints.xy[0][10],)\n",
    "    else:\n",
    "        angle1 =  calculate_angle(keypoints.xy[0][5],\n",
    "                                keypoints.xy[0][11],\n",
    "                                keypoints.xy[0][13],)\n",
    "        angle2 =  calculate_angle(keypoints.xy[0][11],\n",
    "                                keypoints.xy[0][13],\n",
    "                                keypoints.xy[0][15],)\n",
    "        angle3 = calculate_angle(keypoints.xy[0][5],\n",
    "                                keypoints.xy[0][7],\n",
    "                                keypoints.xy[0][9],)\n",
    "    \n",
    "    return angle1>120 and (angle2>120 or angle2<45) and angle3<120\n",
    "\n",
    "\n",
    "def check_push_up_down(keypoints, prev_angle):\n",
    "    angle = get_push_up_angle(keypoints=result.keypoints)\n",
    "    if angle >= prev_angle:\n",
    "        # prev_angle = max(angle, prev_angle)\n",
    "        return True\n",
    "    else:\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_push_up(keypoints, prev_angle):\n",
    "    angle = get_push_up_angle(keypoints=result.keypoints)\n",
    "    if angle < prev_angle:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ],
   "execution_count":96,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"5MjW4y2UKfNvh0Of6ZRPhe",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "<!-- ![yolo keypoints](\/data\/keypoints_yolo.png \"yolo keypoints\") -->\n",
    "<image src=\"\/data\/keypoints_yolo.png\" alt=\"yolo keypoints\">"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ATFa3WT5zMlu5DUAl4dWs1",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def print_count(image, pull_ups, push_ups, squats, person):\n",
    "    org = [20, 100]  # Например, (x, y) = (50, 50)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 4  # Масштаб шрифта\n",
    "    font_color = (0, 200, 0)  # Цвет шрифта в формате BGR   \n",
    "    thickness = 4  # Толщина шрифта\n",
    "    org[1] = org[1] + (person - 1) * 400\n",
    "    # text = \"person: {0} \".format(person)\n",
    "    # cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    # org[1] += 100\n",
    "    text = \"pull ups: {0} \".format(pull_ups)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 100\n",
    "    text = \"push ups: {0} \".format(push_ups)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 100\n",
    "    text = \"squats: {0}\".format(squats)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "\n",
    "\n",
    "def print_debag_info(image,  movment_down, prev_angle,position_line):\n",
    "    org = [20, 100]  # Например, (x, y) = (50, 50)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 3  # Масштаб шрифта\n",
    "    font_color = (0, 200, 0)  # Цвет шрифта в формате BGR   \n",
    "    thickness = 3  # Толщина шрифта\n",
    "    org[1] = org[1] + 400\n",
    "    # text = \"{0} \".format(push_ups)\n",
    "    # cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    # org[1] += 100\n",
    "    text = \"movment_down: {0} \".format(movment_down)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 100\n",
    "    text = \"prev_angle: {0} \".format(prev_angle)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 100\n",
    "    text = \"pos= line{0}\".format(position_line)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "\n",
    "# image1 = cv2.imread(\"data\/push_up1.jpg\")\n",
    "# print_count(image1,1,1,1)\n",
    "# cv2.imwrite('cropped_image.jpg', image1)"
   ],
   "execution_count":89,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"8KRx6yvaFEpz7rdyv7ReTx",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "video = cv2.VideoCapture(\"data\/push_ups1.mp4\")\n",
    "# output_path = os.path.join(\"\", \"output2.mp4\")\n",
    "video_info = sv.VideoInfo.from_video_path(\"data\/push_ups1.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output_video = cv2.VideoWriter(\"output3.mp4\", fourcc, video_info.fps ,\n",
    "                               (video_info.width, video_info.height))\n",
    "# result = model(source=\"data\/push_ups1.mp4\", show=False, conf=0.3, save=True)\n",
    "push_up_count = 0\n",
    "pull_up_count = 0\n",
    "squats_count = 0\n",
    "movment_down = True\n",
    "prev_angle = get_push_up_angle(keypoints=result.keypoints)\n",
    "cadr_num = 0\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if cadr_num % 5 == 0:\n",
    "        results = model.predict(frame)\n",
    "        person = 1\n",
    "        # for result in results:\n",
    "        result = results[0]\n",
    "\n",
    "        side = choose_side(keypoints=result.keypoints)\n",
    "        \n",
    "        if check_position_body_line(result.keypoints):\n",
    "            # push_ups подсчёт\n",
    "            if movment_down and check_push_up_down(result.keypoints, prev_angle):\n",
    "                movment_down = False\n",
    "            # else:\n",
    "            # prev_angle = max(get_push_up_angle(keypoints=result.keypoints), prev_angle)\n",
    "            if not movment_down and check_push_up(result.keypoints, prev_angle):\n",
    "                push_up_count += 1\n",
    "                movment_down = True\n",
    "            prev_angle = get_push_up_angle(result.keypoints)\n",
    "            # pull+ups подчё\n",
    "\n",
    "        # print_count(frame, pull_up_count, push_up_count, squats_count, person)\n",
    "        # print_debag_info(frame, movment_down, prev_angle,check_position_body_line(result.keypoints))\n",
    "        # output_video.write(frame)\n",
    "    cadr_num += 1\n",
    "    print_count(frame, pull_up_count, push_up_count, squats_count, person)\n",
    "    output_video.write(frame)\n",
    "    # for box in result.boxes:\n",
    "    #     class_id = result.names[box.cls[0].item()]\n",
    "    #     cords = box.xyxy[0].tolist()\n",
    "    #     cords = [round(x) for x in cords]\n",
    "    #     conf = round(box.conf[0].item(), 2)\n",
    "    #     cv2.rectangle(frame, [cords[0],cords[1]], [cords[2],cords[3]], (0, 255, 0), 2)\n",
    "\n",
    "    # print(\"Object type:\", class_id)\n",
    "    # print(\"Coordinates:\", cords)\n",
    "    # print(\"Probability:\", conf)\n",
    "    # print(\"---\")    \n",
    "\n",
    "video.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "execution_count":99,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "0: 640x384 1 person, 168.6ms\n",
      "Speed: 2.7ms preprocess, 168.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.0ms\n",
      "Speed: 2.5ms preprocess, 85.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 87.6ms\n",
      "Speed: 2.5ms preprocess, 87.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 78.9ms\n",
      "Speed: 5.0ms preprocess, 78.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 79.5ms\n",
      "Speed: 2.6ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.2ms\n",
      "Speed: 2.5ms preprocess, 91.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 79.2ms\n",
      "Speed: 7.7ms preprocess, 79.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 83.0ms\n",
      "Speed: 7.8ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 96.5ms\n",
      "Speed: 2.5ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.0ms\n",
      "Speed: 7.9ms preprocess, 85.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 93.7ms\n",
      "Speed: 2.5ms preprocess, 93.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 83.2ms\n",
      "Speed: 7.9ms preprocess, 83.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.3ms\n",
      "Speed: 7.9ms preprocess, 82.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 79.3ms\n",
      "Speed: 9.3ms preprocess, 79.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 88.0ms\n",
      "Speed: 7.9ms preprocess, 88.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.7ms\n",
      "Speed: 7.9ms preprocess, 82.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.0ms\n",
      "Speed: 7.9ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 82.6ms\n",
      "Speed: 7.9ms preprocess, 82.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 84.7ms\n",
      "Speed: 8.0ms preprocess, 84.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 86.8ms\n",
      "Speed: 2.5ms preprocess, 86.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.8ms\n",
      "Speed: 2.5ms preprocess, 91.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.8ms\n",
      "Speed: 8.0ms preprocess, 85.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 89.6ms\n",
      "Speed: 2.6ms preprocess, 89.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.7ms\n",
      "Speed: 8.0ms preprocess, 91.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 79.4ms\n",
      "Speed: 8.6ms preprocess, 79.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 80.3ms\n",
      "Speed: 7.8ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.5ms\n",
      "Speed: 8.0ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 89.9ms\n",
      "Speed: 2.6ms preprocess, 89.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 94.9ms\n",
      "Speed: 2.5ms preprocess, 94.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.1ms\n",
      "Speed: 7.9ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 77.7ms\n",
      "Speed: 7.9ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.6ms\n",
      "Speed: 7.9ms preprocess, 85.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 81.4ms\n",
      "Speed: 8.0ms preprocess, 81.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.7ms\n",
      "Speed: 2.5ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 102.4ms\n",
      "Speed: 2.5ms preprocess, 102.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 79.8ms\n",
      "Speed: 7.8ms preprocess, 79.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.1ms\n",
      "Speed: 2.5ms preprocess, 82.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 92.4ms\n",
      "Speed: 2.6ms preprocess, 92.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.6ms\n",
      "Speed: 2.6ms preprocess, 91.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 88.1ms\n",
      "Speed: 2.7ms preprocess, 88.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.5ms\n",
      "Speed: 7.9ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.6ms\n",
      "Speed: 2.5ms preprocess, 91.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 81.0ms\n",
      "Speed: 2.4ms preprocess, 81.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.8ms\n",
      "Speed: 7.9ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 81.0ms\n",
      "Speed: 7.9ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 78.1ms\n",
      "Speed: 8.1ms preprocess, 78.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 81.1ms\n",
      "Speed: 7.8ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.5ms\n",
      "Speed: 2.5ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 78.2ms\n",
      "Speed: 7.1ms preprocess, 78.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 92.2ms\n",
      "Speed: 2.5ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 86.6ms\n",
      "Speed: 2.4ms preprocess, 86.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.0ms\n",
      "Speed: 2.6ms preprocess, 84.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.9ms\n",
      "Speed: 7.9ms preprocess, 85.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 83.3ms\n",
      "Speed: 7.9ms preprocess, 83.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 83.7ms\n",
      "Speed: 7.9ms preprocess, 83.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.9ms\n",
      "Speed: 8.0ms preprocess, 91.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 92.0ms\n",
      "Speed: 2.5ms preprocess, 92.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 88.4ms\n",
      "Speed: 8.1ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 92.0ms\n",
      "Speed: 2.7ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 79.9ms\n",
      "Speed: 8.4ms preprocess, 79.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 96.1ms\n",
      "Speed: 2.5ms preprocess, 96.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 83.3ms\n",
      "Speed: 8.8ms preprocess, 83.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.4ms\n",
      "Speed: 2.5ms preprocess, 91.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 103.3ms\n",
      "Speed: 2.5ms preprocess, 103.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.6ms\n",
      "Speed: 7.9ms preprocess, 85.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.2ms\n",
      "Speed: 2.6ms preprocess, 91.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 102.5ms\n",
      "Speed: 2.4ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.4ms\n",
      "Speed: 7.9ms preprocess, 84.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 87.1ms\n",
      "Speed: 2.5ms preprocess, 87.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 80.5ms\n",
      "Speed: 8.1ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 92.3ms\n",
      "Speed: 2.5ms preprocess, 92.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 86.1ms\n",
      "Speed: 7.9ms preprocess, 86.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 83.1ms\n",
      "Speed: 7.8ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.8ms\n",
      "Speed: 7.9ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.8ms\n",
      "Speed: 7.9ms preprocess, 91.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 81.9ms\n",
      "Speed: 7.9ms preprocess, 81.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 92.4ms\n",
      "Speed: 7.9ms preprocess, 92.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.7ms\n",
      "Speed: 2.4ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 101.4ms\n",
      "Speed: 2.7ms preprocess, 101.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.4ms\n",
      "Speed: 2.5ms preprocess, 91.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 93.6ms\n",
      "Speed: 2.6ms preprocess, 93.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 86.4ms\n",
      "Speed: 2.5ms preprocess, 86.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.5ms\n",
      "Speed: 8.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.2ms\n",
      "Speed: 2.5ms preprocess, 85.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 80.3ms\n",
      "Speed: 2.5ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.7ms\n",
      "Speed: 7.9ms preprocess, 84.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 95.2ms\n",
      "Speed: 2.6ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 86.8ms\n",
      "Speed: 2.5ms preprocess, 86.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 90.4ms\n",
      "Speed: 2.5ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 86.1ms\n",
      "Speed: 7.9ms preprocess, 86.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 80.7ms\n",
      "Speed: 7.0ms preprocess, 80.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 76.8ms\n",
      "Speed: 7.3ms preprocess, 76.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.2ms\n",
      "Speed: 7.8ms preprocess, 84.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.2ms\n",
      "Speed: 2.4ms preprocess, 85.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 97.1ms\n",
      "Speed: 2.5ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 81.8ms\n",
      "Speed: 8.1ms preprocess, 81.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 80.3ms\n",
      "Speed: 7.6ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.1ms\n",
      "Speed: 2.5ms preprocess, 85.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.1ms\n",
      "Speed: 7.9ms preprocess, 82.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 91.3ms\n",
      "Speed: 2.5ms preprocess, 91.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 82.3ms\n",
      "Speed: 2.5ms preprocess, 82.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.8ms\n",
      "Speed: 2.4ms preprocess, 85.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 86.8ms\n",
      "Speed: 2.5ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 79.3ms\n",
      "Speed: 7.8ms preprocess, 79.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 80.5ms\n",
      "Speed: 7.9ms preprocess, 80.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 84.6ms\n",
      "Speed: 7.9ms preprocess, 84.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 88.5ms\n",
      "Speed: 2.5ms preprocess, 88.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 90.8ms\n",
      "Speed: 2.4ms preprocess, 90.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 87.0ms\n",
      "Speed: 2.4ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 89.4ms\n",
      "Speed: 8.0ms preprocess, 89.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 99.1ms\n",
      "Speed: 2.5ms preprocess, 99.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 87.0ms\n",
      "Speed: 2.5ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 87.7ms\n",
      "Speed: 8.1ms preprocess, 87.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 85.8ms\n",
      "Speed: 7.9ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 89.9ms\n",
      "Speed: 2.8ms preprocess, 89.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 95.2ms\n",
      "Speed: 2.6ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 87.1ms\n",
      "Speed: 2.7ms preprocess, 87.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 94.9ms\n",
      "Speed: 2.4ms preprocess, 94.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"LgIz8qhInUPIMGCiyt0SAa",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    "xKSlI0JGy2HZioEJGpzMq0",
    "QhLR0xVildZuep6oRDTrdN",
    "9Xbrseg7AHEAbOznNortIM"
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}