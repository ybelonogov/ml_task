{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# этап 1 \n",
    "## нахождение на видео человека\n",
    "\n"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"si2nsBzsXZAvnJSGHsRmXz",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"xKSlI0JGy2HZioEJGpzMq0"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!pip install ultralytics\n",
    "!pip install clearml\n",
    "!pip install supervision"
   ],
   "execution_count":148,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: ultralytics in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (8.1.20)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (3.7.1)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (4.9.0.80)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (10.2.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (6.0.1)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (2.30.0)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (1.10.0)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (2.0.1+cpu)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (0.15.2+cpu)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (4.66.1)\r\n",
      "Requirement already satisfied: psutil in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (5.9.8)\r\n",
      "Requirement already satisfied: py-cpuinfo in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: thop>=0.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (0.1.1.post2209072238)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (1.5.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from ultralytics) (0.12.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: numpy>=1.20 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.3.0->ultralytics) (6.1.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\r\n",
      "Requirement already satisfied: filelock in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (1.12)\r\n",
      "Requirement already satisfied: networkx in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\r\n",
      "Requirement already satisfied: six>=1.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Requirement already satisfied: clearml in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (1.14.4)\r\n",
      "Requirement already satisfied: attrs>=18.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (23.2.0)\r\n",
      "Requirement already satisfied: furl>=2.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.1.3)\r\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (4.21.0)\r\n",
      "Requirement already satisfied: numpy>=1.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (1.24.3)\r\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.3.7.post1)\r\n",
      "Requirement already satisfied: Pillow>=4.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (10.2.0)\r\n",
      "Requirement already satisfied: psutil>=3.4.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (5.9.8)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.8.2)\r\n",
      "Requirement already satisfied: PyYAML>=3.12 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (6.0.1)\r\n",
      "Requirement already satisfied: requests>=2.20.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.30.0)\r\n",
      "Requirement already satisfied: six>=1.13.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (1.26.18)\r\n",
      "Requirement already satisfied: pyjwt<2.9.0,>=2.4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (2.8.0)\r\n",
      "Requirement already satisfied: referencing<0.40 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from clearml) (0.32.1)\r\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from furl>=2.0.0->clearml) (1.0.1)\r\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (6.1.1)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (2023.12.1)\r\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (1.3.10)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jsonschema>=2.6.0->clearml) (0.17.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.20.0->clearml) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.20.0->clearml) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests>=2.20.0->clearml) (2023.11.17)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6.0->clearml) (3.17.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Requirement already satisfied: supervision in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (0.18.0)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (0.7.1)\r\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (3.7.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (1.24.3)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (4.7.0.72)\r\n",
      "Requirement already satisfied: pyyaml>=5.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (6.0.1)\r\n",
      "Requirement already satisfied: scipy==1.10.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from supervision) (1.10.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (4.47.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (23.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from matplotlib>=3.6.0->supervision) (6.1.1)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.6.0->supervision) (3.17.0)\r\n",
      "Requirement already satisfied: six>=1.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"7h5GfATsJ0Owpl4TH0vTR6",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"9Xbrseg7AHEAbOznNortIM"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv"
   ],
   "execution_count":149,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"qXPHkOFoPRqKHVFOmtDjpi",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"QhLR0xVildZuep6oRDTrdN"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model = YOLO(\"yolov8n-pose.pt\")"
   ],
   "execution_count":199,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"GNqtvG1nU96yzhkYChR3ZS",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "image = cv2.imread(\"data\/push_up1.jpg\")\n",
    "results = model(source=\"data\/right.jpg\", show=False, conf=0.3, save=True)\n",
    "results = model(source=\"data\/push_up1.jpg\", show=False, conf=0.3, save=True)\n",
    "\n",
    "result = results[0]\n",
    "results"
   ],
   "execution_count":151,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "image 1\/1 \/data\/notebook_files\/data\/right.jpg: 640x512 1 person, 117.2ms\n",
      "Speed: 3.6ms preprocess, 117.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Results saved to \u001b[1mruns\/pose\/predict5\u001b[0m\n",
      "\n",
      "image 1\/1 \/data\/notebook_files\/data\/push_up1.jpg: 640x288 1 person, 87.2ms\n",
      "Speed: 10.9ms preprocess, 87.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
      "Results saved to \u001b[1mruns\/pose\/predict5\u001b[0m\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/plain":[
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8)\n",
       " orig_shape: (2400, 1080)\n",
       " path: '\/data\/notebook_files\/data\/push_up1.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\/pose\/predict5'\n",
       " speed: {'preprocess': 10.947227478027344, 'inference': 87.16797828674316, 'postprocess': 1.0516643524169922}]"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"GVCuwUWSnIdnCfGXTEfX9C",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def calculate_distance(keypoints, idx1, idx2):\n",
    "    x1, y1 = keypoints.xy[0][idx1]\n",
    "    x2, y2 = keypoints.xy[0][idx2]\n",
    "    if keypoints.has_visible:\n",
    "        distance = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "        return distance\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def choose_side(keypoints):\n",
    "    r_shoulder = calculate_distance(keypoints, 6, 8)\n",
    "    l_shoulder = calculate_distance(keypoints, 5, 7)\n",
    "    return r_shoulder > l_shoulder"
   ],
   "execution_count":152,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"PxNZ9he641HX8CZ33QStc7",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First\n",
    "    b = np.array(b)  # Mid\n",
    "    c = np.array(c)  # End\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 \/ np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle "
   ],
   "execution_count":153,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"UsTsh1M0hx0WEqMifLbUYP",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def check_position_body_line(keypoints):\n",
    "    if side:\n",
    "        #распремлена поясница\n",
    "        angle1 = calculate_angle(keypoints.xy[0][6],\n",
    "                                 keypoints.xy[0][12],\n",
    "                                 keypoints.xy[0][14], )\n",
    "        #распрямлены ноги\n",
    "        angle2 = calculate_angle(keypoints.xy[0][12],\n",
    "                                 keypoints.xy[0][14],\n",
    "                                 keypoints.xy[0][16], )\n",
    "        #изгиб локтя\n",
    "        angle3 = calculate_angle(keypoints.xy[0][6],\n",
    "                                 keypoints.xy[0][8],\n",
    "                                 keypoints.xy[0][10], )\n",
    "    else:\n",
    "        angle1 = calculate_angle(keypoints.xy[0][5],\n",
    "                                 keypoints.xy[0][11],\n",
    "                                 keypoints.xy[0][13], )\n",
    "        angle2 = calculate_angle(keypoints.xy[0][11],\n",
    "                                 keypoints.xy[0][13],\n",
    "                                 keypoints.xy[0][15], )\n",
    "        angle3 = calculate_angle(keypoints.xy[0][5],\n",
    "                                 keypoints.xy[0][7],\n",
    "                                 keypoints.xy[0][9], )\n",
    "\n",
    "    # return angle1 > 120 and (angle2 > 120 or angle2 < 45) and angle3 < 120\n",
    "    return angle1 + angle2 > 260 and angle3 < 120\n",
    "\n",
    "\n",
    "def get_push_up_angle(keypoints):\n",
    "    if side:\n",
    "        angle = calculate_angle(keypoints.xy[0][6],\n",
    "                                keypoints.xy[0][8],\n",
    "                                keypoints.xy[0][12],\n",
    "                                ) - calculate_angle(keypoints.xy[0][6],\n",
    "                                                    keypoints.xy[0][8],\n",
    "                                                    keypoints.xy[0][10], )\n",
    "    else:\n",
    "        angle = calculate_angle(keypoints.xy[0][5],\n",
    "                                keypoints.xy[0][7],\n",
    "                                keypoints.xy[0][11],\n",
    "                                ) - calculate_angle(keypoints.xy[0][5],\n",
    "                                                    keypoints.xy[0][7],\n",
    "                                                    keypoints.xy[0][9], )\n",
    "    return angle\n",
    "\n",
    "\n",
    "def check_push_up_down(keypoints, prev_angle):\n",
    "    angle = get_push_up_angle(keypoints=result.keypoints)\n",
    "    if angle >= prev_angle:\n",
    "        # prev_angle = max(angle, prev_angle)\n",
    "        return True\n",
    "    else:\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_push_up(keypoints, prev_angle):\n",
    "    angle = get_push_up_angle(keypoints=result.keypoints)\n",
    "    if angle < prev_angle:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ],
   "execution_count":181,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"5MjW4y2UKfNvh0Of6ZRPhe",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def check_position_legs_bent(keypoints):\n",
    "    if side:\n",
    "        #распремлена поясница\n",
    "        angle1 = calculate_angle(keypoints.xy[0][6],\n",
    "                                 keypoints.xy[0][12],\n",
    "                                 keypoints.xy[0][14], )\n",
    "        #распрямлены ноги\n",
    "        angle2 = calculate_angle(keypoints.xy[0][12],\n",
    "                                 keypoints.xy[0][14],\n",
    "                                 keypoints.xy[0][16], )\n",
    "    else:\n",
    "        angle1 = calculate_angle(keypoints.xy[0][5],\n",
    "                                 keypoints.xy[0][11],\n",
    "                                 keypoints.xy[0][13], )\n",
    "        angle2 = calculate_angle(keypoints.xy[0][11],\n",
    "                                 keypoints.xy[0][13],\n",
    "                                 keypoints.xy[0][15], )\n",
    "    return angle1 + angle2 < 260\n",
    "\n",
    "\n",
    "def get_squats_angls(keypoints):\n",
    "    if side:\n",
    "        # колено\n",
    "        angle1 = calculate_angle(keypoints.xy[0][12],\n",
    "                                 keypoints.xy[0][14],\n",
    "                                 keypoints.xy[0][16], )\n",
    "        # таз\n",
    "        angle2 = calculate_angle(keypoints.xy[0][6],\n",
    "                                 keypoints.xy[0][12],\n",
    "                                 keypoints.xy[0][14], )\n",
    "    else:\n",
    "        angle1 = calculate_angle(keypoints.xy[0][11],\n",
    "                                 keypoints.xy[0][13],\n",
    "                                 keypoints.xy[0][15], )\n",
    "        angle2 = calculate_angle(keypoints.xy[0][5],\n",
    "                                 keypoints.xy[0][11],\n",
    "                                 keypoints.xy[0][13], )\n",
    "    return angle1, angle2\n",
    "\n",
    "\n",
    "def check_squats_down(keypoints, prev_angls):\n",
    "    angls = get_squats_angls(keypoints)\n",
    "    if angls[0] + angls[1] > prev_angls[1] + prev_angls[0]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_squats_up(keypoints, prev_angls):\n",
    "    angls = get_squats_angls(keypoints)\n",
    "    if angls[0] + angls[1] < prev_angls[1] + prev_angls[0]:\n",
    "        return True\n",
    "    return False"
   ],
   "execution_count":188,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"USPjkZFTxFpfc73VeM7xLl",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def check_pull_ups(keypoints, movment_down):\n",
    "    return "
   ],
   "execution_count":156,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"9Wv7iZF7RzYQwlL59QrKoj",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "<!-- ![yolo keypoints](\/data\/keypoints_yolo.png \"yolo keypoints\") -->\n",
    "<image src=\"\/data\/keypoints_yolo.png\" alt=\"yolo keypoints\">"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ATFa3WT5zMlu5DUAl4dWs1",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def print_count(image, pull_ups, push_ups, squats, person):\n",
    "    org = [20, 100]  # Например, (x, y) = (50, 50)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 4  # Масштаб шрифта\n",
    "    font_color = (0, 200, 0)  # Цвет шрифта в формате BGR   \n",
    "    thickness = 6  # Толщина шрифта\n",
    "    org[1] = org[1] + (person - 1) * 400\n",
    "    # text = \"person: {0} \".format(person)\n",
    "    # cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    # org[1] += 100\n",
    "    text = \"pull ups: {0} \".format(pull_ups)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 100\n",
    "    text = \"push ups: {0} \".format(push_ups)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 100\n",
    "    text = \"squats: {0}\".format(squats)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "\n",
    "\n",
    "def print_debag_info(image, movment_down, prev_angle, position_line, pos_squat):\n",
    "    org = [20, 100]  # Например, (x, y) = (50, 50)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 2  # Масштаб шрифта\n",
    "    font_color = (0, 200, 0)  # Цвет шрифта в формате BGR   \n",
    "    thickness = 2  # Толщина шрифта\n",
    "    org[1] = org[1] + 400\n",
    "    # text = \"{0} \".format(push_ups)\n",
    "    # cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    # org[1] += 100\n",
    "    text = \"movment_down: {0} \".format(movment_down)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 50\n",
    "    text = \"prev_angle: {0} \".format(prev_angle)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 50\n",
    "    text = \"pos= line: {0}\".format(position_line)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "    org[1] += 50\n",
    "    text = \"pos= squat: {0}\".format(pos_squat)\n",
    "    cv2.putText(image, text, org, font, font_scale, font_color, thickness)\n",
    "\n",
    "# image1 = cv2.imread(\"data\/push_up1.jpg\")\n",
    "# print_count(image1,1,1,1)\n",
    "# cv2.imwrite('cropped_image.jpg', image1)"
   ],
   "execution_count":194,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"8KRx6yvaFEpz7rdyv7ReTx",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "video = cv2.VideoCapture(\"data\/push_up4.mp4\")\n",
    "# output_path = os.path.join(\"\", \"output2.mp4\")\n",
    "video_info = sv.VideoInfo.from_video_path(\"data\/push_up4.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output_video = cv2.VideoWriter(\"output6.mp4\", fourcc, video_info.fps,\n",
    "                               (video_info.width, video_info.height))\n",
    "# result = model(source=\"data\/push_ups1.mp4\", show=False, conf=0.3, save=True)\n",
    "push_up_count = 0\n",
    "pull_up_count = 0\n",
    "squats_count = 0\n",
    "movment_down = True\n",
    "prev_angle = get_push_up_angle(keypoints=result.keypoints)\n",
    "cadr_num = 0\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if cadr_num % 5 == 0:\n",
    "        results = model.predict(frame)\n",
    "        person = 1\n",
    "        # for result in results:\n",
    "        result = results[0]\n",
    "        side = choose_side(keypoints=result.keypoints)\n",
    "        # push_ups подсчёт \n",
    "        if check_position_body_line(result.keypoints) and not check_position_legs_bent(result.keypoints):\n",
    "\n",
    "            if movment_down and check_push_up_down(result.keypoints, prev_angle):\n",
    "                movment_down = False\n",
    "            if not movment_down and check_push_up(result.keypoints, prev_angle):\n",
    "                push_up_count += 1\n",
    "                movment_down = True\n",
    "        prev_angle = get_push_up_angle(result.keypoints)\n",
    "        # print_count(frame, pull_up_count, push_up_count, squats_count, person)\n",
    "        # print_debag_info(frame, movment_down_squats, prev_angls[0] ,\n",
    "        #                  check_position_body_line(result.keypoints),\n",
    "        #                  check_position_legs_bent(result.keypoints))\n",
    "        # output_video.write(frame)\n",
    "\n",
    "    cadr_num += 1\n",
    "    print_count(frame, pull_up_count, push_up_count, squats_count, person)\n",
    "    output_video.write(frame)\n",
    "\n",
    "video.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "execution_count":206,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "0: 384x640 1 person, 194.0ms\n",
      "Speed: 2.5ms preprocess, 194.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.0ms\n",
      "Speed: 7.9ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.1ms\n",
      "Speed: 2.4ms preprocess, 94.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.7ms\n",
      "Speed: 7.7ms preprocess, 88.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.5ms\n",
      "Speed: 9.7ms preprocess, 84.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 96.6ms\n",
      "Speed: 2.4ms preprocess, 96.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 83.9ms\n",
      "Speed: 7.8ms preprocess, 83.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 87.9ms\n",
      "Speed: 7.8ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 89.0ms\n",
      "Speed: 7.7ms preprocess, 89.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 85.1ms\n",
      "Speed: 7.9ms preprocess, 85.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 94.1ms\n",
      "Speed: 2.4ms preprocess, 94.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 92.9ms\n",
      "Speed: 2.5ms preprocess, 92.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.8ms\n",
      "Speed: 2.5ms preprocess, 82.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 88.8ms\n",
      "Speed: 2.4ms preprocess, 88.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 83.9ms\n",
      "Speed: 8.0ms preprocess, 83.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.6ms\n",
      "Speed: 2.3ms preprocess, 93.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 88.7ms\n",
      "Speed: 2.3ms preprocess, 88.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.7ms\n",
      "Speed: 7.8ms preprocess, 89.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.0ms\n",
      "Speed: 7.8ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.3ms\n",
      "Speed: 7.7ms preprocess, 82.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.8ms\n",
      "Speed: 2.3ms preprocess, 87.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.3ms\n",
      "Speed: 2.3ms preprocess, 86.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.5ms\n",
      "Speed: 7.8ms preprocess, 83.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.8ms\n",
      "Speed: 2.4ms preprocess, 89.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.5ms\n",
      "Speed: 2.4ms preprocess, 86.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.8ms\n",
      "Speed: 2.3ms preprocess, 87.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.1ms\n",
      "Speed: 7.8ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 89.9ms\n",
      "Speed: 2.3ms preprocess, 89.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 85.9ms\n",
      "Speed: 7.8ms preprocess, 85.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 87.9ms\n",
      "Speed: 2.3ms preprocess, 87.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.7ms\n",
      "Speed: 2.4ms preprocess, 82.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 84.1ms\n",
      "Speed: 7.7ms preprocess, 84.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 98.6ms\n",
      "Speed: 2.3ms preprocess, 98.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 94.2ms\n",
      "Speed: 2.3ms preprocess, 94.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 81.7ms\n",
      "Speed: 7.8ms preprocess, 81.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 95.3ms\n",
      "Speed: 2.4ms preprocess, 95.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.6ms\n",
      "Speed: 2.4ms preprocess, 85.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.5ms\n",
      "Speed: 7.8ms preprocess, 83.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.3ms\n",
      "Speed: 2.4ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.7ms\n",
      "Speed: 7.9ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.1ms\n",
      "Speed: 2.3ms preprocess, 88.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.3ms\n",
      "Speed: 2.5ms preprocess, 89.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 2.4ms preprocess, 76.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.2ms\n",
      "Speed: 2.4ms preprocess, 88.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.1ms\n",
      "Speed: 7.8ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.7ms\n",
      "Speed: 2.4ms preprocess, 89.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 90.3ms\n",
      "Speed: 2.4ms preprocess, 90.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 91.4ms\n",
      "Speed: 7.8ms preprocess, 91.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 79.7ms\n",
      "Speed: 2.5ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 89.1ms\n",
      "Speed: 2.4ms preprocess, 89.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.2ms\n",
      "Speed: 7.8ms preprocess, 84.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 89.1ms\n",
      "Speed: 2.4ms preprocess, 89.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.5ms\n",
      "Speed: 7.8ms preprocess, 82.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 85.8ms\n",
      "Speed: 2.4ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 77.1ms\n",
      "Speed: 2.9ms preprocess, 77.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.8ms\n",
      "Speed: 7.8ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.8ms\n",
      "Speed: 2.5ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.0ms\n",
      "Speed: 7.7ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.6ms\n",
      "Speed: 7.8ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.8ms\n",
      "Speed: 7.8ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.5ms\n",
      "Speed: 2.4ms preprocess, 79.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.0ms\n",
      "Speed: 7.8ms preprocess, 82.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.9ms\n",
      "Speed: 7.8ms preprocess, 82.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.1ms\n",
      "Speed: 7.7ms preprocess, 82.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.4ms\n",
      "Speed: 7.8ms preprocess, 82.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 88.5ms\n",
      "Speed: 2.4ms preprocess, 88.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 79.0ms\n",
      "Speed: 3.5ms preprocess, 79.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 89.2ms\n",
      "Speed: 2.4ms preprocess, 89.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 78.0ms\n",
      "Speed: 9.3ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 80.0ms\n",
      "Speed: 9.2ms preprocess, 80.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 83.7ms\n",
      "Speed: 7.8ms preprocess, 83.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 94.5ms\n",
      "Speed: 2.4ms preprocess, 94.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.6ms\n",
      "Speed: 2.4ms preprocess, 93.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 91.5ms\n",
      "Speed: 2.3ms preprocess, 91.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.6ms\n",
      "Speed: 2.3ms preprocess, 93.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 92.4ms\n",
      "Speed: 2.4ms preprocess, 92.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.0ms\n",
      "Speed: 2.4ms preprocess, 93.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 94.3ms\n",
      "Speed: 7.8ms preprocess, 94.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 77.3ms\n",
      "Speed: 7.6ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 97.9ms\n",
      "Speed: 2.6ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 80.2ms\n",
      "Speed: 6.5ms preprocess, 80.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"LgIz8qhInUPIMGCiyt0SAa",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "video = cv2.VideoCapture(\"data\/squats.mp4\")\n",
    "# output_path = os.path.join(\"\", \"output2.mp4\")\n",
    "video_info = sv.VideoInfo.from_video_path(\"data\/squats.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output_video = cv2.VideoWriter(\"output5.mp4\", fourcc, video_info.fps,\n",
    "                               (video_info.width, video_info.height))\n",
    "# result = model(source=\"data\/push_ups1.mp4\", show=False, conf=0.3, save=True)\n",
    "push_up_count = 0\n",
    "pull_up_count = 0\n",
    "squats_count = 0\n",
    "movment_down = True\n",
    "movment_down_squats = True\n",
    "prev_angle = get_push_up_angle(keypoints=result.keypoints)\n",
    "prev_angls = get_squats_angls(keypoints=result.keypoints)\n",
    "cadr_num = 0\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if cadr_num % 5 == 0:\n",
    "        results = model.predict(frame)\n",
    "        person = 1\n",
    "        # for result in results:\n",
    "        result = results[0]\n",
    "        side = choose_side(keypoints=result.keypoints)\n",
    "\n",
    "        # squats подчёт\n",
    "        if check_position_legs_bent(result.keypoints):\n",
    "            if movment_down_squats and check_squats_down(result.keypoints, prev_angls):\n",
    "                movment_down_squats = False\n",
    "            if not movment_down_squats and check_squats_up(result.keypoints, prev_angls):\n",
    "                movment_down_squats = True\n",
    "                # squats_count += 1\n",
    "        prev_angls = get_squats_angls(result.keypoints)\n",
    "\n",
    "        # print_count(frame, pull_up_count, push_up_count, squats_count, person)\n",
    "        # print_debag_info(frame, movment_down_squats, prev_angls[0] ,\n",
    "        #                  check_position_body_line(result.keypoints),\n",
    "        #                  check_position_legs_bent(result.keypoints))\n",
    "        # output_video.write(frame)\n",
    "\n",
    "    cadr_num += 1\n",
    "    print_count(frame, pull_up_count, push_up_count, squats_count, person)\n",
    "    output_video.write(frame)\n",
    "\n",
    "video.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "execution_count":202,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "0\n",
      "12\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"DPrXTkKu7XB7RPUZSlUdxv",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "push_up_count"
   ],
   "execution_count":208,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "10"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Zs4mSEqtMRIyi5lLd7oP75",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    "xKSlI0JGy2HZioEJGpzMq0",
    "QhLR0xVildZuep6oRDTrdN",
    "9Xbrseg7AHEAbOznNortIM"
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}